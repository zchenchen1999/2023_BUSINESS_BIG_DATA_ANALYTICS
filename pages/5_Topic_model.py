import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
from st_files_connection import FilesConnection

# è² è²¬äººï¼šç•‡å½¤


# é è¨­é¡¯ç¤º wide mode
st.set_page_config(page_title="Nissan PTT è¨è«–ä¸»é¡Œåˆ†æ", layout="wide", page_icon="ğŸ“ˆ")
# st.set_option('dataframe.fit_columns_to_available_width', True)

# title
st.title("Nissan PTT è¨è«–ä¸»é¡Œåˆ†æ")


st.markdown(
    f""" #### ä¸»é¡Œæ¨¡å‹èªªæ˜:
    - å·¦é‚Šçš„åœ“åœˆä»£è¡¨ä¸åŒçš„ä¸»é¡Œï¼Œåœ“åœˆå¤§å°ä»£è¡¨è©²ä¸»é¡Œçš„è¨è«–é‡
    - å³é‚Šè—è‰²çš„é•·æ¢åœ–ä»£è¡¨ PTT ä¸­æåˆ°è©²è©å½™çš„ç¸½æ¬¡æ•¸
    - å³é‚Šç´…è‰²çš„é•·æ¢åœ–æ¯”ä¾‹è¶Šé«˜ä»£è¡¨è©²è©å½™è¶Šé›†ä¸­åœ¨ç•¶å‰çš„ä¸»é¡Œä¸­
    """, unsafe_allow_html=True)

# ä¸»é¡Œæ¨¡å‹ html è®€å–
path = './html_files/nissan_lda.html'
with open(path, 'r') as f :
    HtmlFile = f.read()
components.html(HtmlFile, height=900, scrolling=True)


# ä¸»é¡Œæ¨¡å‹æè¿° dataframe
st.markdown('#### åˆ†æçµæœèªªæ˜')
topic = {
    '': ['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5'],
    'ä¸»é¡Œé—œéµå­— (åƒ…åˆ—å‡ºéƒ¨åˆ†)': ['æ¥­å‹™ã€é ç®—ã€ç©ºé–“ã€åƒ¹æ ¼ã€ä¸éŒ¯ã€éš”éŸ³ã€å®‰å…¨ã€è©¦ä¹˜ã€å¾Œåº§', 
              'è£•éš†ã€ä¸­åœ‹ã€æ—¥æœ¬ã€è±ç”°ã€å¸‚å ´ã€é€²å£ã€ç¾åœ‹ã€é›»å‹•è»Šã€åœ‹ç”¢ã€éŠ·é‡ã€æ­æ´²ã€æˆæœ¬',
              'åŸå» ã€ä¿é¤Šã€è®Šé€Ÿç®±ã€é‡Œç¨‹ã€æ²¹è€—ã€å¤–è§€ã€ä¿å›ºã€å¼•æ“ã€å¸‚å€ã€å…§è£ã€å¦¥å–„ã€ç¶­ä¿®',
              'æŠ˜åƒ¹ã€ç©ºè»Šã€è´ˆé€ã€æ›æ–°ã€åŒ—éƒ¨ã€ç¾é‡‘ã€äº¤è»Šè£¡ã€æ——è‰¦ç‰ˆã€èœå–®',
              'é¡è‰²ã€æ’æª”ã€å½¢å¼ã€è‡ªç”¨ã€ä¸€æ‰‹ã€ç™½è‰²ã€ç¨…é‡‘ã€è¦è²»ã€çœ‹è»Š'],
    'ä¸»é¡Œ': ['è³¼è»ŠåŸºæœ¬è€ƒé‡', 'å…¨çƒå¸‚å ´åŠç›¸é—œè­°é¡Œ', 'æ±½è»Šæ™‚å¸¸è¨è«–è­°é¡Œ', 'è³¼è»Šèœå–®', 'æ±½è»Šè²·è³£']
}

topic_df = pd.DataFrame(topic)
st.dataframe(topic_df, use_container_width=True, hide_index=True)



# é—œéµå­—æŸ¥è©¢
conn = st.experimental_connection('gcs', type=FilesConnection)

@st.cache_data(persist=True)  # ğŸ‘ˆ Add the caching decorator
def load_data(url):
    csv_data = conn.read(url, input_format="csv", ttl=None)
    return csv_data
nissan = load_data("big-data-class-2023/nissan_clean_data.csv")

## å®šç¾©æ–‡ç« æŸ¥æ‰¾ function
def get_article(word):
    try:
        findword = nissan.loc[nissan['words'].str.contains(word)]
        findword = findword[['artTitle', 'artDate', 'artCatagory', 'artContent', 'artUrl']]
        return findword
    except KeyError:
        return []

st.markdown('#### é—œéµå­—æœå°‹')

word = st.text_input("è«‹è¼¸å…¥é—œéµå­—:")

if word:
    relative_art = get_article(word)
    if relative_art.empty:
        st.write("æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–‡ç« .")
    else:
        st.dataframe(relative_art,     
                     column_config = {
                        "artTitle": "æ–‡ç« æ¨™é¡Œ",
                        "artDate": "ç™¼æ–‡æ—¥æœŸ",
                        "artCatagory": "æ–‡ç« ç‰ˆåˆ¥",
                        "artContent": "æ–‡ç« å…§å®¹",
                        "artUrl": "æ–‡ç« é€£çµ",
                    },
                    use_container_width=True,
                    hide_index=True)
        st.write('é—œéµå­—', word,'å…±æ‰¾åˆ° ',len(relative_art), ' ç¯‡æ–‡ç« ')