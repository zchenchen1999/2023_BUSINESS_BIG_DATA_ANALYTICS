import streamlit as st
# from google.oauth2 import service_account
# from gsheetsdb import connect
import pandas as pd
from st_files_connection import FilesConnection

# é è¨­é¡¯ç¤º wide mode
st.set_page_config(page_title="è£•æ—¥æœ‰æœ›å®¢åˆ†æç³»çµ±", layout="wide")

# title
st.title("è£•æ—¥æœ‰æœ›å®¢åˆ†æç³»çµ±")

car_brand = ["nissan", "toyota", "ford", "honda", "mazda"]

# è®€å–è¼‰å…¥ dataï¼Œè‹¥è¼¸å…¥åƒæ•¸åœ¨å…ˆå‰ streamlit å·²çœ‹éï¼Œå‰‡æœƒç›´æ¥è®€å» cache ä¸­çš„çµæœï¼ˆä¸åŸ·è¡Œ defï¼‰
#              è‹¥è¼¸å…¥åƒæ•¸æ²’çœ‹éï¼Œå‰‡æœƒåŸ·è¡Œ def
#              ä¸åªæœ‰è®€å– data å¯ä½¿ç”¨ï¼Œ UI ä¹Ÿå¯ä»¥ï¼ˆå¦‚æœè¦ºå¾—æ¯æ¬¡ç•«åœ–è©±å¾ˆä¹…ï¼Œå¯ä»¥æ”¾åœ¨ cache ä¸­çš„ function åŸ·è¡Œï¼‰=> è¼¸å…¥åƒæ•¸æ²’è®Šæœƒç›´æ¥é¡¯ç¤ºä¹‹å‰ç•«å¥½çš„åœ–
conn = st.experimental_connection('gcs', type=FilesConnection)

@st.cache_data(persist=True)  # ğŸ‘ˆ Add the caching decorator
def load_data(url):
    csv_data = conn.read(url, input_format="csv", ttl=None)
    return csv_data
    
# nissan = load_data("big-data-class-2023/rawData/nissan_ptt_data.csv")
# toyota = load_data("big-data-class-2023/rawData/toyota_ptt_data.csv")
# ford = load_data("big-data-class-2023/rawData/ford_ptt_data.csv")
# honda = load_data("big-data-class-2023/rawData/honda_ptt_data.csv")
# mazda = load_data("big-data-class-2023/rawData/mazda_ptt_data.csv")

# @st.cache_data(persist=True)
# def show_ptt_data():
#     st.header("å¤–éƒ¨åŸå§‹è³‡æ–™")
#     nissan_tab, toyota_tab, ford_tab, honda_tab, mazda_tab = st.tabs(car_brand)
#     nissan_tab.dataframe(nissan)
#     toyota_tab.dataframe(toyota)
#     ford_tab.dataframe(ford)
#     honda_tab.dataframe(honda)
#     mazda_tab.dataframe(mazda)



# å…§éƒ¨è³‡æ–™
st.header("å…§éƒ¨è³‡æ–™")
# è®€å–å…§éƒ¨è³‡æ–™
internal = load_data("big-data-class-2023/rawData/nissan_internal.csv")
st.dataframe(internal)
# # é¡¯ç¤ºå¤–éƒ¨è³‡æ–™
# show_ptt_data()
